---
layout: post
title: "Big and Small Data"
date: 2016-09-12
---

I listened to two great podcasts on my drive through New York this weekend. The first was TED Radio Hour's [Big Data Revolution](http://www.npr.org/programs/ted-radio-hour/492296605/big-data-revolution). The second was Radiolab's [Playing God](http://www.npr.org/programs/ted-radio-hour/492296605/big-data-revolution).

They were related in a few interesting ways. TED Radio Hour focused on the potential of big data in society. Self driving cars, finding early warning signs to deadly diseases, discovering secrets of the universe, and more, offer the biggest opportunity for advancement since the beginning of the information age.

But big data comes with risks as well, the podcast points out. It could lead to issues like [racial profiling](https://www.thenation.com/article/big-data-actually-reinforcing-social-inequalities/). There is potential for inherent bias in the way an algorithm is built that could lead to negative outcomes for certain types of people. Machine learning algorithms do not have the context to consider. That is where people come in. People can assess if the algorithm is not performing properly, or is profiling people in a way that we as humans do not accept.

Ethics are key when embarking on a big data project.

And that is where Radiolab's episode came in. The show focuses on triage during mass casualty incidents. How does someone make a decision about who lives and who dies in an impossible situation? During Hurricane Katrina, doctors and nurses in a hospital in New Orleans had to make judgments about which patients could be saved, and which could not, given the circumstances. Dozens died because the resources were not available to transfer everyone to other medical facilities. The question arose: given that some patients were terminally ill, is it appropriate to 'put them out of their misery'?

Following Hurricane Katrina, there were many discussions about setting standards to help make these kinds of decisions. When triaging patients, should the sickest get the first treatment? Should the youngest patients, even if they were not as sick? Do some patients have more values than others?

After the earthquake in Haiti, one person responsible for triaging patients in Haiti determined that a patient with heart failure should be taken off oxygen because there were others who were not terminally ill who needed it, and had a better chance of surviving. This decision was made without the person managing triage ever meeting the patient.

Similar to a big data project where the algorithm does not know context, this triage manager did not know the context of this patient's life, either. The reporter for the story had gotten to know the patient, and knew that all of the staff had grown to like the patient.

The triage manager, in his capacity, followed protocol and possibly made the utilitarian choice to help the most people, rather than an individual. The reporter on the story stayed with the patient and helped get the patient more medical care - ultimately extending her life slightly. The reporter said that the patient was able to raise money for others in need during the remaining months of her life, and the perspective of this case changed the reporter's life. So was this patient worth saving, even though her illness ultimately proved deadly?

Big data projects are nothing without context and ethics. Triage during mass casualty incidents can be impossible if context is always taken into account and there are no absolute standards.

Our world will continue to rely on data more heavily, and there will surely be mass casualty incidents in the future, unfortunately. Data could lend a hand in determining the most efficient ways to apply scarce resource during one of these incidents. But relying solely on an algorithm while taking the human element out would be a mistake, too.
